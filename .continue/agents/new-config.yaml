name: Gemini Proxy Config
version: 1.0.0
schema: v1
models:
  - name: "üöÄ Codestral Latest"
    model: "codestral-latest"
    provider: mistral
    apiKey: "jwAmH3oVZ3MlkCdaw0Ip61mZZWco3UOt"
    contextLength: 32000
  - name: "‚ö° deep-research-pro-preview-12-2025"
    model: "deep-research-pro-preview-12-2025"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° nano-banana-pro-preview"
    model: "nano-banana-pro-preview"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-3-pro-image-preview"
    model: "gemini-3-pro-image-preview"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-3-pro-preview"
    model: "gemini-3-pro-preview"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-pro-latest"
    model: "gemini-pro-latest"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-2.5-pro-preview-tts"
    model: "gemini-2.5-pro-preview-tts"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-2.5-pro"
    model: "gemini-2.5-pro"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-2.5-flash"
    model: "gemini-2.5-flash"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-2.0-flash"
    model: "gemini-2.0-flash"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-2.0-flash-001"
    model: "gemini-2.0-flash-001"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-2.0-flash-exp-image-generation"
    model: "gemini-2.0-flash-exp-image-generation"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-2.0-flash-lite-001"
    model: "gemini-2.0-flash-lite-001"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-2.0-flash-lite"
    model: "gemini-2.0-flash-lite"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-exp-1206"
    model: "gemini-exp-1206"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-2.5-flash-preview-tts"
    model: "gemini-2.5-flash-preview-tts"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemma-3-1b-it"
    model: "gemma-3-1b-it"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemma-3-4b-it"
    model: "gemma-3-4b-it"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemma-3-12b-it"
    model: "gemma-3-12b-it"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemma-3-27b-it"
    model: "gemma-3-27b-it"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemma-3n-e4b-it"
    model: "gemma-3n-e4b-it"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemma-3n-e2b-it"
    model: "gemma-3n-e2b-it"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-flash-latest"
    model: "gemini-flash-latest"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-flash-lite-latest"
    model: "gemini-flash-lite-latest"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-2.5-flash-lite"
    model: "gemini-2.5-flash-lite"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-2.5-flash-image"
    model: "gemini-2.5-flash-image"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-2.5-flash-preview-09-2025"
    model: "gemini-2.5-flash-preview-09-2025"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-2.5-flash-lite-preview-09-2025"
    model: "gemini-2.5-flash-lite-preview-09-2025"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-3-flash-preview"
    model: "gemini-3-flash-preview"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-robotics-er-1.5-preview"
    model: "gemini-robotics-er-1.5-preview"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000
  - name: "‚ö° gemini-2.5-computer-use-preview-10-2025"
    model: "gemini-2.5-computer-use-preview-10-2025"
    provider: openai
    apiBase: "http://localhost:13337/v1"
    apiKey: "sk-local-proxy"
    contextLength: 128000

tabAutocompleteModel:
  title: "Codestral Autocomplete"
  model: "codestral-latest"
  provider: mistral
  apiKey: "jwAmH3oVZ3MlkCdaw0Ip61mZZWco3UOt"

tabAutocompleteOptions:
  useCopyBuffer: true
  useFileSuffix: true
  maxPromptTokens: 2048
  debounceDelay: 75
  multilineCompletions: "always"
  disableInFiles:
    - "*.md"
    - "*.txt"
    - ".env"

experimental:
  modelRoles:
    nextEdit:
      provider: mistral
      model: "codestral-latest"
      apiKey: "jwAmH3oVZ3MlkCdaw0Ip61mZZWco3UOt"

context:
  - provider: open
    params:
      onlyPinned: false
  - provider: currentFile
  - provider: repo-map
    params:
      includeSignatures: true
  - provider: code
  - provider: tree
  - provider: terminal
  - provider: problems
  - provider: diff
  - provider: clipboard
  - provider: debugger
    params:
      stackDepth: 5
  - provider: os

systemMessage: |
  B·∫°n l√† m·ªôt chuy√™n gia l·∫≠p tr√¨nh cao c·∫•p. Lu√¥n tu√¢n th·ªß c√°c nguy√™n t·∫Øc Clean Code (SOLID, DRY, KISS). 
  Khi vi·∫øt code:
  1. Tuy·ªát ƒë·ªëi kh√¥ng bao gi·ªù th√™m comment v√†o trong m√£ ngu·ªìn.
  2. M√£ ngu·ªìn ph·∫£i lu√¥n ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t v√† b·ªô nh·ªõ ·ªü m·ª©c cao nh·∫•t.
  3. Cung c·∫•p gi·∫£i ph√°p to√†n di·ªán, ho√†n thi·ªán 100%, kh√¥ng vi·∫øt code gi·∫£ (placeholder) ho·∫∑c b·ªè d·ªü (lazy coding).
  4. Lu√¥n ch·ªß ƒë·ªông ƒë·ªÅ xu·∫•t ki·∫øn tr√∫c t·ªët h∆°n n·∫øu gi·∫£i ph√°p hi·ªán t·∫°i ch∆∞a t·ªëi ∆∞u.
  5. Code ph·∫£i d·ªÖ ƒë·ªçc th√¥ng qua vi·ªác ƒë·∫∑t t√™n bi·∫øn v√† h√†m t∆∞·ªùng minh thay v√¨ d√πng gi·∫£i th√≠ch b·∫±ng ch·ªØ.
